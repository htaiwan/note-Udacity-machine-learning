# 樸素貝葉斯

## Agenda

- [簡介](#1)
- [猜測人](#2)
- [已知與推斷](#3)
- [再次猜測](#4)
- [貝葉斯定理](#5)
- [誤報](#6)
- [貝葉斯學習](#7)
- [樸素貝葉斯算法](#8)
- [構建垃圾郵件分類器](#9)

## Note

<h2 id="1">簡介</h2>

> - 樸素貝葉斯是一種機率算法。
> - 易於實現，並且訓練速度快。

<h2 id="2">猜測人</h2>

![106](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/106.png)

> - Prior: 先驗機率，在還沒拿到新訊息(紅毛衣)之前所做的推斷(假設兩個人在公司的時間一樣長)。
> - Posterior: 後驗機率，在拿到新訊息(紅毛衣)之後所做的推斷。

<h2 id="3">已知與推斷</h2>

![107](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/107.png)

> - 已知: Alex和Brenda穿著紅毛衣的機率。
> - 推斷: 穿著紅毛衣的人是Alex還是Brenda的機率。

![108](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/108.png)

> - 一開始知道事件A的機率(兩個人在公司的時間一樣長)
> - 已知: 事件R(Alex和Brenda穿著紅毛衣的機率)在事件A條件下發生的機率。
> - 推斷: 事件A在事件R發生下的機率。

<h2 id="4">再次猜測</h2>

![111](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/111.png)

> - Alex一週來三天，Brenda一週來一天。
> - 以列來觀察，每一列Alex出現的次數是Brenda三倍。

![109](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/109.png)

> - Alex一週穿二次紅毛衣，Brenda一週穿三次紅毛衣。
> - 以列來觀察，Brenda會多穿一次紅毛衣。
> - 剩下紅色部分: 6/9 Alex 3/9 Brenda

![110](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/110.png)

> - 從數學角度來觀察: P(A|R) + P(B|R) = 1

<h2 id="5">貝葉斯定理</h2>

![112](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/112.png)

> - 已知: 事件A,B的機率，又分別知道事件R與A,B的關聯性。
> - 推斷: 事件R下，事件A,B的機率為如何。

<h2 id="6">誤報</h2>

![113](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/113.png)

> - 99%準確度的測試
> - 0.01%的患病機率

**被測試出真正患病的機率是多少??**

![114](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/114.png)

> - P(+|S): 有生病且真的被診斷出生病 (True Positive)
> - P(+|H): 沒有生病但卻被診斷出生病 (False Postivie)
> - 套用貝葉斯定理計算出P(S|+): 被診斷出來有生病且真的生病的機率 0.98%

![115](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/115.png)

> - 從實例計算來理解公式。

**99%的準確度測試，那被診斷出來有生病且真的生病的機率應該要0.99%，為什麼是0.98%**

![116](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/116.png)

> - 這一切都是因為False Postivie的影響。
> - 也就是說被誤診的可能性遠遠超過實際患病的可能性(這也是0.99變成0.98的原因)。

<h2 id="7">貝葉斯學習</h2>

![117](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/117.png)

> - 已知:
> 
> > - 1/3: 在垃圾郵件中有easy的機率。
> > - 2/3: 在垃圾郵件中有money的機率。
>
> - 推斷: 
> 
> > - 1/2: 在有easy時是垃圾郵件的機率。
> > - 2/3: 在有money時是垃圾郵件的機率。

![118](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/118.png)

> - 進一步推斷: 
> 
> > - 1/3: 在有easy和money時是垃圾郵件的機率。

![119](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/119.png)

> - 利用圖形來解釋在有easy時是垃圾郵件的機率。

![120](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/120.png)

> - 利用圖形來解釋在有money時是垃圾郵件的機率。

<h2 id="8">樸素貝葉斯算法</h2>

**樸素貝葉斯算法的兩大核心**

![121](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/121.png)

**1. Naive Assumption**

> - 假設A和B為獨立互斥事件。
> - 這樣的假設我們稱做navie，因為這種假設實際是天真，不成立的假設，但卻可以幫助我們有效簡化計算。


**2. Conditonal probability**

![122](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/122.png)

> - 核心定律。

![123](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/123.png)

> - 把定律中左邊P(B)移掉，進行簡化，變成定律左右兩邊是一個比例關系，而不是相等關係。

**垃圾郵件例子**

![124](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/124.png)

> - 先使用核心定律的簡化公式。

![125](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/125.png)

> - 套用Naive Assumption，轉化公式的右邊。

![126](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/126.png)

![127](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/127.png)

> - 最後計算出兩個數字
> - 1/12: 當有easy, money時，是垃圾郵件的機率跟1/12有比例關系。
> - 1/30: 當有easy, money時，是一般郵件的機率跟1/30有比例關系。

![128](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/128.png)

![129](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/129.png)

> - 進行轉化，讓1/12和1/30這兩個數字轉化後，相加等於1。

<h2 id="9">構建垃圾郵件分類器</h2>

**項目簡介**

![130](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/130.png)

**項目概述**

![131](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/131.png)

[構建垃圾郵件分類器](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Jupyter/Bayesian_Inference-zh.ipynb)