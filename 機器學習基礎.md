# 機器學習基礎

## Agenda

- **訓練與測試模型**
	-  [概述](#1)
	-  [統計學知識複習](#2)
	-  [pandas加載數據](#3)
	-  [numpy數組](#4)
	-  [在sklearn中訓練模型](#5)
	-  [手動調整參數](#6)
	-  [自動調整參數](#7)
	-  [測試模型](#8)

- **評估指標**
	-  [混淆矩陣](#9)
	-  [準確率](#10)
	-  [準確率不適用的情況](#11)
	-  [假負例與假正例](#12)
	-  [精度](#13)
	-  [招回率](#14)
	-  [F-1得分](#15)
	-  [F-B得分](#16)
	-  [ROC曲線](#17)
	-  [回歸指標](#18)

- **模型選擇**
	-  [錯誤類型](#19)
	-  [模型複雜度圖表](#20)
	-  [交叉驗證](#21)
	-  [學習曲線](#22)
	-  [網格搜索](#23)
	-  [在sklearn中進行網格搜索](#24)

## Note

<h2 id="1">概述</h2>

![1](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/1.png)

> - Problem: 現實中機器學習所要解決的問題。
> - Tools: 機器學習的算法(線性迴歸,邏輯回歸,svm,神經網路..等等)。
> - Mesurement Tools: 來評估用哪個tool解決問題最有效率。

**本章重點就是學習如何使用 Mesurement Tools。**

<h2 id="2">統計學知識複習</h2>

> - 居中趋势测量：均值、中值、众数。
> - 数据的离散性：四分位距法、异常值、标准偏差、贝塞尔修正。

<h2 id="3">pandas加載數據</h2>

> - [Pandas 介绍](https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/3-1-pd-intro/)
> - [官方資源](http://pandas.pydata.org/pandas-docs/stable/tutorials.html)

<h2 id="4">numpy數組</h2>

> - [Numpy 介绍](https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/2-1-np-attributes/)
> - [官方資源](https://docs.scipy.org/doc/numpy/user/quickstart.html)


<h2 id="5">在sklearn中訓練模型</h2>

```python
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC

classifier = LogisticRegression() # 逻辑回归
classifier = MLPClassifier() # 神经网络
classifier = GradientBoostingClassifier() # 决策树
classifier = SVC() # 支持向量机

classifier.fit(X,y) # 進行模型訓練
```

<h2 id="6">手動調整參數</h2>

> - 例子，SVM模型有下列參數
> 
> > - kernel: linear (线性)， poly（多项式）, rbf（高斯核）
> > - degree（整型）：多项式内核的次数（如果选择了多项式内核）
> > - gamma （浮点型）：γ 参数
> > - C（浮点型）：C 参数 

```python
from sklearn.svm import SVC

classifier = SVC(kernel = 'poly', degree = 2) # 手動進行參數調整
classifier.fit(X,y) # 進行模型訓練
```

<h2 id="7">自動調整參數</h2>

> - 如何選擇正確的算法與參數。
> - 如何評估訓練好的模型好壞。

<h2 id="8">測試模型</h2>

![2](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/2.png)

> - 利用train_test_split將資料分成訓練跟測試兩組。

![3](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/3.png)

**黃金準則:千萬不能把測試資料拿去訓練模型 !!!**


<h2 id="9">混淆矩陣</h2>

![4](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/4.png)

> - True Positive: 有生病，且被診斷出來有生病。
> - True Negative: 沒有生病，且被診斷出來沒有生病。
> - False Postive: 沒有生病，但被診斷出來有生病。
> - False Negative: 有生病，但被診斷出來沒有生病。

<h2 id="10">準確率</h2>

![5](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/5.png)

> - 在所有就診中，我們正確的分類有多少？
> - 可以利用sklearn中的accurany_score進行計算。

<h2 id="11">準確率不適用的情況</h2>

![6](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/6.png)

> - 對於這種極度偏斜的數據，準確率就不適用了。

<h2 id="12">假負例與假正例</h2>

- **在不同情況下，我們會注意不同的假負例與假正例**

![7](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/7.png)

> - 在醫療例子下，會強調False Negative，因為比較不希望沒有診斷出生病的人。

![8](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/8.png)

> - 在拉圾郵件例子下，會強調False Positive，因為比較不希望把非拉圾郵件給丟掉。


<h2 id="13">精度</h2>

![9](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/9.png)

> - 精度: 當模型診斷出是病人時，真的是病人有多少?

![10](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/10.png)

> - 精度: 當模型判斷出是拉圾郵件時，真的是拉圾郵件有多少?

<h2 id="14">招回率</h2>

![11](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/11.png)

> - 招回率: 在所有病人中，真的被模型診斷出是病人有多少?

![12](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/12.png)

> - 招回率: 在所有拉圾郵件中，真的被模型判斷出是拉圾郵件有多少?


<h2 id="15">F-1得分</h2>

![13](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/13.png)

> - 如何用一個數字，就可以代替精度和招回率兩種指標呢?

![14](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/14.png)

> - F1 Score: 也是一種平均的概念，但一般來說會小於真的平均數。
> - 调和平均数，强调了较小值的重要性；在机器学习中。召回率为R, 准确率为P。使用他们对算法的评估，这两个值通常情况下相互制约。为了更加方便的评价算法的好坏。于是引入了F1值。F1为准确率P和召回率R的调和平均数。为什么F1使用调和平均数，而不是数字平均数。举个例子：当R 接近于1, P 接近于 0 时。采用调和平均数的F1值接近于0；而如果采用算数平均数F1的值为0.5；显然采用调和平均数能更好的评估算法的性能。等效于评价R和P的整体效果

<h2 id="16">F-B得分</h2>

![15](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/15.png)

> - F-B Score: 可以讓我們更彈性去根據模型的需求給予分數，強調精度或招回率。

![16](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/16.png)

> - 寄送免费样品是需要成本，所以我們希望在所有被寄出的客人中，真的會喜歡這樣品的客人數越多越好。

![17](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/17.png)

<h2 id="17">ROC曲線</h2>

**Receiver Operating Characteristic**

![18](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/18.png)

![19](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/19.png)

> - 如果模型是可以把資料進行很好的"Good split"，計算橫軸上不同切點上的True positive rate跟False positive rate。

![20](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/20.png)

> - ROC的X軸: False positive rate。
> - ROC的Y軸: True positive rate。

![21](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/21.png)

> - 結論: 當模型的ROC下的面積越接近1，表現越好。

<h2 id="18">回歸指標</h2>

**評估回歸模型的指標。**

![22](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/22.png)
> - 平均絕對誤差。
> - 絕對值函數是無法微分，不利於梯度下降的計算。

![23](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/23.png)
> - 均方誤差。

![24](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/24.png)
> - R2 score。 
> - 將模型與最簡單的可能模型相比得出。
> 
> > - 最簡單的可能模型(分母的圖): 計算所有點的平均，畫出這條平均水平線。
> > - 理論上，這個最簡單的可能模型均方誤差要大於我們模型的均方誤差。
> 
> - R2 = 0，表示分子跟分母相近，也就是模型表現並不好(基本上，就是算平均而已)。
> - R2 = 1，表示分母遠大於分子，也就是模型表現的越好。


<h2 id="19">錯誤類型</h2>

![25](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/25.png)

> - underfitting: 拿蒼蠅拍打哥吉拉(太低估哥吉拉) 
> - overfitting: 拿衝鋒槍打蒼蠅(太高估蒼蠅)

![26](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/26.png)

> - underfitting: training set和test set表現都很糟糕。
> - overfitting: trainig set表現很好但test set表現很糟糕。

<h2 id="20">模型複雜度圖表</h2>

**Model complexity graph**

![27](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/27.png)

> - Linear Model: 在training set跟test set都分錯3個點。(underfitting)
> - Quadratic Model: 在training set跟test set都分錯1個點。
> - Polynomial Mode: 在trainig set沒分錯，但在test set卻分錯2個點。(overfitting)

![30](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/30.png)

> - gerneal model complexity graph

![28](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/28.png)

**黃金準則:千萬不能把測試資料拿去訓練模型 !!!**

> - 解決方式: 就是交叉驗證。

<h2 id="21">交叉驗證</h2>

![29](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/29.png)

> - 將資料從2份拆分成3份。

**K-Fold Cross Validation**

![31](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/31.png)

> - 將training data和test data個拆分成K堆。
> - 每次訓練都從K堆挑出一組training data和test data，這樣可進行K次訓練。
> - 最後再將K次訓練的結果進行平均。

![32](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/32.png)

> - 如何利用sklearn進行K-Fold Cross Validation。

<h2 id="22">學習曲線</h2>

**Learning curve**

![33](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/33.png)

> - 隨著測試數據的增多，來觀察模型的學習變化進而判斷模型的狀況(overfiiting, underfitting, good)。
> - High bias(underfitting): 隨著測試數據的增多，但CV error跟Training error一直很高，降不下來。
> - High variance(overfitting): 隨著測試數據的增多，Training error一直很低，但CV error還是很高，兩者之間有很大的gap。

<h2 id="23">網格搜索</h2>

![34](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/34.png)

> - SVM model訓練，有兩組超參數。
> - 兩組超參數利用grid table，生成不同配對後，分別利用training set進行訓練。
> - 將訓練好的model，再利用cross validation set，分別計算F1 score。
> - 最後，將分數最高的model，再利用test test進行測試。

<h2 id="24">在sklearn中進行網格搜索</h2>

```python
from sklearn.metrics import make_scorer
from sklearn.model_selection import GridSearchCV

clf = DecisionTreeClassifier(random_state=42)

# 定义一些参数来执行网格搜索。使用max_depth, min_samples_leaf, 和 min_samples_split
parameters = {'max_depth':[2,4,6,8,10],'min_samples_leaf':[2,4,6,8,10], 'min_samples_split':[2,4,6,8,10]}

# 使用f1_score，为模型制作记分器
scorer = make_scorer(f1_score)

# 使用参数和记分器，在分类器上执行网格搜索。
grid_obj = GridSearchCV(clf, parameters, scoring=scorer)

# 将数据拟合到新的分类器中
grid_fit = grid_obj.fit(X_train, y_train)

# 找到最佳參數組合的分類器
best_clf = grid_fit.best_estimator_

# 将数据拟合到最佳的分类器中.
best_clf.fit(X_train, y_train)

# 將這最佳的分类器，再利用test test進行測試.
best_train_predictions = best_clf.predict(X_train)
best_test_predictions = best_clf.predict(X_test)

# 計算最佳的分类器在trainig跟testing的f1_score.
print('The training F1 Score is', f1_score(best_train_predictions, y_train))
print('The testing F1 Score is', f1_score(best_test_predictions, y_test))

# Plot the new model.
plot_model(X, y, best_clf)

# Let's also explore what parameters ended up being used in the new model.
best_clf

```
