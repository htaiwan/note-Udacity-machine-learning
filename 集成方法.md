# 集成方法

## Agenda

- [簡介](#1)
- [Bagging](#2)
- [AdaBoost](#3)
- [數據權重](#4)
- [為模型賦值](#5)
- [集合模型](#6)
- [sklearn 中的 AdaBoost](#7)
- [AdaBoost 上的学习资源](#8)


## Note

<h2 id="1">簡介</h2>

**Ensemble Methods**

- Bagging & Boosting

![161](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/161.png)

> - **Bagging**
> - 讓每個人都做過一遍這個測試，最後再將結果結合再一起。
> - 如果是數值型，也許就是取平均，如果是是非題，也許就是多數決。

![162](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/162.png)

> - **Boosting**
> - 讓不同擅長的人來處理不同的問題，最後再將結果結合再一起。

![163](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/163.png)

> - **Weak Learner**，把原本一群的朋友，當作所謂的弱學習器。
> - **Strong Learner**，把集合成一體，當作所謂的強學習器。

<h2 id=2"">Bagging</h2>

![164](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/164.png)

> - 假設，我們有三個弱學習器。

![165](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/165.png)

> - 接下來，我們有一組資料，如果用這三個弱學習器去學習，會發現學習效果都不是很好。

![166](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/166.png)

![167](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/167.png)

![168](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/168.png)

> - **重點**
> - **將原本的資料任意拆分成三個子集合，然後分別交給三個弱學習器去學習。**

![169](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/169.png)

> - **最後將三個三個弱學習器的學習結果集合起來。**
> - 這個例子，可以透過疊加的方式來進行集合，若藍色多的點就是為藍色，若紅色多的點就回紅色。
> - 若是一樣的多點，就隨機決定，但在實際情況下若弱學習器很多的話，必較不容易出先一樣多的情況。

![170](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/170.png)

> - 三個臭皮匠的智慧結果。


<h2 id="3">AdaBoost</h2>

**自適應增強算法**

![171](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/171.png)

![172](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/172.png)

![173](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/173.png)

> - **重點: 下一個weak learner要去修正上一個weak learner所犯的錯誤。**

![174](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/174.png)

> - 將3個weak learner的結果賦予權重進行疊加。

<h2 id="4">數據權重</h2>

![175](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/175.png)

> - 假設，一開始每個點的權重都是1。

![176](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/176.png)

> - 第一個weak learner分錯3個點。
> - 正確的點權重和: 7  
> - 錯誤的點權重和: 3
> - **重點: 調整錯誤的點的權重，讓錯誤的點的權重和要等於正確的點權重和。**
> - 調整後，錯誤的點的權重 7/3 = 2.33。

![177](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/177.png)

> - 下一個weak learner要去修正上一個weak learner所犯的錯誤。
> - 正確的點權重和: 7/3x3 + 1x4 = 11  
> - 錯誤的點權重和: 3
> - 調整後，錯誤的點的權重 11/3 = 3.66。

![178](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/178.png)

> - 可以繼續重複上面的步驟，繼續下去。
> - 但方便之後討論，先做到這裡。

![179](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/179.png)

> - 現在得到3個不同的model，該要學習如何合併。

<h2 id="5">為模型賦值</h2>

![180](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/180.png)

> - 先從一個假設開始，哪種朋友最不可靠?
> - **一半說謊，一半實話這種朋友最不可靠，因為永遠不清楚何時該相信他。**

![181](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/181.png)

> - 在模型角度討論，準確度只有一半的模型最不可靠，他的權重應該要最低。

![182](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/182.png)

![183](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/183.png)

> - 權重函數，可以透過sigmoid function來給予。

![184](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/184.png)

> - 上面三個model的權重應該要分別是多少?

![185](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/185.png)

> - 討論edge case，出現這樣的權重的模型表示是十分完美正確的模型，但只有存在理論的幻想空間裡，實作上不太有可能遇到。


<h2 id="6">集合模型</h2>

![186](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/186.png)

![187](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/187.png)

![188](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/188.png)

![189](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/189.png)

> - 根據上節所學到如何給模型賦值，替這3個weak learner分別給於適當的權重。

**重點: 集合模型，如何將weak learner進行合併**

![190](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/190.png)

> - 先放入model 1的weight到對應的區域。

![191](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/191.png)

> - 合併model 2的weight到對應的區域。

![192](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/192.png)

> - 合併model 3的weight到對應的區域。

![193](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/193.png)

> - 進行權重相加，產生最後的結果。

<h2 id="7">sklearn 中的 AdaBoost</h2>

![194](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/194.png)

<h2 id="8">AdaBoost 上的学习资源</h2>

[原始論文](https://cseweb.ucsd.edu/~yfreund/papers/IntroToBoosting.pdf)

[後續論文](https://people.cs.pitt.edu/~milos/courses/cs2750/Readings/boosting.pdf)

[教程](hhttps://www.csie.ntu.edu.tw/~mhyang/course/u0030/papers/schapire.pdf)