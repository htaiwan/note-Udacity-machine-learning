# 層次聚類法與密度聚類

## Agenda

- [K-均值聚類](#1)
- [其他聚類方法概述](#2)
- [單連接聚類法](#3)
- [檢驗單連接聚類法](#4)
- [三種不同的層次聚類法](#5)
- [層次聚類法的具體使用](#6)
- [LAB 層次聚類法](#7)
- [層次聚類法的優缺點](#8)
- [密度聚類法(DBSCAN)](#9)
- [DBSCAN運行](#10)
- [LAB DBSCAN](#11)
- [DBSCAN的優缺點](#12)

## Note

<h2 id="1">K-均值聚類</h2>

- K-Means是一個很重要的分類算法，但在某些特定的數據集因為算法的限制，無法成功分類這些數據，因此我們需要學習一些其他分類算法，來彌補K-Means的不足。

![391](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/391.png)


<h2 id="2">其他聚類方法概述</h2>

- **層次聚類**: 層次聚類的結果更可以幫助我們了解類之間的關係。

- **密度聚類**: 會著重其中一種算法叫做**DBSCAN**，對於噪音數據有很強的適用性。這種算法對於雙月牙型數據特別有用。

![392](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/392.png)

<h2 id="3">單連接聚類法</h2>

- **單連接聚類法**: 關注是類與類之間的最短距離。
	- 計算某個點到某一類中所有點的距離，找出最短距離。
	- 重複上述步驟，計算出某個點到所有類的最短距離。
	- 選出最短距離的類，然後進行連接。

- **Dendrogram**: 系統樹圖。
	- 對於高維度的數據，可以透過這個圖來進行視覺化分析。
	- 也可以分析出直接用單連接聚類法的缺陷。

![393](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/393.png)

<h2 id="4">檢驗單連接聚類法</h2>

- 單連接聚類法: 再處理雙月牙跟雙環數據明顯優於K-Means。
- 缺點: 常常會導致有個**巨大類**的產生。但可以透過系統樹圖分析後來改善這樣的巨大類的產生，不能直接用單連接聚類法的結果，而是要將樹在橫切成多個分類。

![394](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/394.png)

<h2 id="5">三種不同的層次聚類法</h2>

**Complete link clustering**: 關注是類與類之間的最遠距離。

![395](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/395.png)

**Average link clustering**: 關注是類與類之間的平均距離。

![396](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/396.png)

**Ward's Method**: Scikit-learn的default值。

![397](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/397.png)


<h2 id="6">層次聚類法的具體使用</h2>

![398](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/398.png)

![399](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/399.png)

<h2 id="7">LAB 層次聚類法</h2>

[LAB 層次聚類法](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Jupyter/Hierarchical_Clustering_Lab-zh.ipynb)

<h2 id="8">層次聚類法的優缺點</h2>

- 優點: 
	- 可以得到層次表達，幫助我們分析。
	- 可以將數據集的聚類結構視覺化。
	- 對於數據內部有層次關係時，更有明顯的優勢，例如進化生物學。

- 缺點:
	- 對於數據中的噪音跟偏差值很敏感，需要提前清理這類數據。
	- 計算量大。

![400](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/400.png)

<h2 id="9">密度聚類法(DBSCAN)</h2>

- [可视化 DBSCAN 聚类](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)

- **Input**:
	- 給定某個距離(半徑)，尋找此範圍下所包含的其他點。
	- 給定點數量，超過這個數量才視為是真的cluster。
- **Noise Point**: 找不到任何cluster的點。
- **Core Point**: cluster的中心點。
- **Border Point**: Cluster的邊界點。

![401](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/401.png)

- 與K-Means進行比較:

![402](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/402.png)

<h2 id="10">DBSCAN運行</h2>

![403](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/403.png)

<h2 id="11">LAB DBSCAN</h2>

[LAB 層次聚類法](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Jupyter/DBSCAN_Notebook-zh.ipynb)

<h2 id="12">DBSCAN的優缺點</h2>

- 優點: 
	- 不用指定cluster數量。
	- 能靈活找到各種不同形狀和大小的cluster。
	- 可以處理噪音跟偏差值。
	
- 缺點:
	- DBSCAN不能保證每次都回傳相同的cluster結果。由於Border point可能被不同cluster所佔據。
	- 找到不同密度的cluster有一定的困難。

![404](https://github.com/htaiwan/note-Udacity-machine-learning/blob/master/Assets/404.png)
